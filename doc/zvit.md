# Пояснювальна записка
## Зміст
1. [Вступ](#вступ)
2. [Технічне завдання](#завдання)
3. [Основні положення](#теорія)
4. [Проектування](#проектування)
5. [Розробка](#розробка)
6. [Тестування](#тести)
7. [Висновки](#висновки)
8. [Джерела](#джерела)

<a name="вступ"></a>
## Вступ
**Мета:**
Метою документа є з'ясування основних вимог до функціональності та експлуатаційної придатності, а також визначення бізнес-правил і можливих технологічних обмежень предмета розробки.

**Агент вибірки даних з медіа ресурсу** – це автономна частина системи збору інформації, що дозволяє отримати дані за конкретним запитом для подальшого їх аналізу.

Агенти вибірки даних створюються для спрощення процесів вибірки інформації з неструктурованих текстових повідомлень з таких інформаційних джерел, як веб-ресурси, інтернет-видання, відкриті телеграм-канали, соціальні мережі тощо.
В даній роботі ми будемо використовувати соціальну мережу Reddit, а саме новинні канали, де постійно оновлюються пости з інформацією.
Метою даної курсової роботи є розробити та реалізувати закінчений програмний продукт мовою JavaScript, а також, поглибити знання та розширити навички в розробці алгоритмів і їх реалізації. Наш агент вибірки даних буде збирати інформацію з вказаної кількості постів, що оприлюднені на обраних каналах Reddit.
В майбутньому агент може використовуватися у ролі постачальника інформації спеціалізованим системам для її аналізу.

**Реалізація:**
Для реалізації проекту використовувались наступні технології та фреймворки:  IntelliJ Idea, UML, JavaScript, Puppeteer, Axios, Cheerio, Node.js.

<a name="завдання"></a>
## Технічне завдання

**Загальне завдання:**
Розробити застосунок, що грає роль агента вибірки даних і надає можливість отримання потрібної інформації з певних ресурсів.

**Функціональність**
- користувач повинен мати можливість обрати інформаційні канали Reddit
- користувач повинен мати можливість змінити кількість опрацьованих постів

<a name="теорія"></a>
## Основні положення
**Мас-медіа** — засоби передавання, зберігання та відтворення інформації, призначені для її донесення крізь просторові, часові чи інші перепони. Наприклад технічні засоби та канали комунікації, такі як радіо, телебачення, інтернет, поширення знімних носіїв інформації, що формують особливе середовище комунікації.

**Соціальні медіа** — вид мас-медіа, ряд онлайнових технологій на, завдяки яким споживачі контенту через свої дописи стають його співавторами і можуть взаємодіяти, співпрацювати, спілкуватися, ділитися інформацією або брати участь у будь-якій інший соціальній активності із теоретично усіма іншими користувачами певного сервісу.

**Контент-аналіз** — якісно-кількісний метод вивчення документів, який характеризується об'єктивністю висновків і строгістю процедури та полягає у квантифікаційній обробці тексту з подальшою інтерпретацією результатів.

**Reddit**  — це розважальний, новинний онлайн-сервіс, а також інтернет-ЗМІ, де зареєстровані користувачі можуть додавати свій контент, такий як текстові пости або прямі посилання й обговорювати їх.

**Веб-скрапінг** — це метод збору даних з веб-сайтів. Цей термін зазвичай використовується в застосуванні до автоматизованого збору даних.

**Axios** — це JavaScript-бібліотека для виконання або HTTP-запитів в Node.js, або XMLHttpRequests в браузері.

**Node.js** — платформа з відкритим кодом для виконання високопродуктивних мережевих застосунків, написаних мовою JavaScript.

<a name="проектування"></a>
## Проектування
Користувачеві потрібні дані певної кількості постів з обраних каналів Reddit. Запускаючи програму, користувач може вказати скільки конкретно постув треба опрацювати. Агент вирушає за вказаними адресами і викачує потрібні дані. Після успішного завершення роботи програми, користувач отримує файл, де збережено всі дані за запитом.

![usecase](http://www.plantuml.com/plantuml/png/HKub5W904CtO7UPjHYDkSJCL9-6MSMWqNAw0kvpXpubm6VVvhdmXb2iKamcDKgCCHGhf75amn9NBs7E5grp34dDkMIYK9wbHFhcOZqL2-HW9JBdw7CJvCLB5dhYB2zTVsyzIaxlS9km8Inmnn-wXbyVT1c6DBJQFiGrEuddQvmqOJS_ZadIwdCxnBxXYgUW3tnq0)

![scenario1](http://www.plantuml.com/plantuml/png/SoWkIImgAStDuULAJ2x9Br88BKujukLApiyhAShFKL1oJ4_DAr422UJaf2QNPERd5Iie-QQcP2Og1EUN5YMd0kL0MXHqxH2AeGoW68PQ53vG1QOsi23K6GwfUIb0jm40)

### Сценарій
       
***НАЗВА:*** Отримати інформацію з вказаних джерел

***УЧАСНИКИ:*** Користувач, застосунок

***ПЕРЕДУМОВИ:*** Користувач хоче отримати інформацію з певних джерел

***РЕЗУЛЬТАТ:*** Користувач отримав файл з викачаною інформацією

***ВИКЛЮЧНІ СИТУАЦІЇ:***
 - EХ.001 Технічні збої  

***ОСНОВНИЙ СЦЕНАРІЙ:*** 
1. Користувач запускає застосунок.
2. Застосунок виконує свою задачу (можлива EХ.001).
3. Застосунок видає користувачу файл з потрібною інформацією.

![scenario](http://www.plantuml.com/plantuml/png/TL0rLWH15CpxlRx3I8o5kD-147UdYN2FSDU8VDrtUwvG_qPKDvAnE_xhb_LjcB5rixcqgDKsNc1b7sKva4CvGXPfETlMoYEqwWZmY3GIEP83L3cx2_Yo3uiShsdKvQXJAz8ucAE0vVK83IAgGV_CrBBPzYmtAFlzCpAH8y_TXZm4A0MKv00bzuKsJjomY0Bf2wYHV7d5J0NhSpEp9eYdfyVuqwfhl2V06oo1DPJ9OB-_3OyqjxQsQJMrF1cuFQsy-AUFMFVISaoX2cfEMXxGuBiVqjkfFCYTNFX0_pT3lWz-uE274Gbn_42sZ8k0ofz8fojoPPMtFbfYuLy0)

<a name="розробка"></a>
## Розробка
Принцип роботи програми базується на проєкті tg-scrapper. 
Працює агент так: 
1. Формується список джерел - посилань на канали;
2. Цей список ітерується, для кожного з джерел ініциалізується скрипт, який створює браузер, формується посилання, де джерело передається як параметр і програма переходить в новій вкладці по цьому посиланню;
3. Далі по селекторам вибираються потрібні дані і записуються в список, відповідно джерелу;
4. Після завершення ітерації списки записуються у файл.

Перелік використаних при розробці модулів:
- fs - модуль дозволяє взаємодіяти з файловою системою
- puppeteer - бібліотека надає доступ до високо-рівневого API, що дозволяє керувати Chrome або Chromium через DevTools Protocol
- chalk - модуль дозволяє змінювати формат повідомлень, що виводяться до консолі
- cliProgress - модуль дозволяє створювати шкалу прогресу, що виводитья до консолі
- queue-promise - бібліотека дозволяє створювати черги засновані на запитах. Дозволяє виконувати певні дії після виконання чи відхилення завдання.

**Діаграма класів**
![photo2](https://github.com/sofiaguchenko/agent/blob/main/doc/ph/photo_2021-05-20_19-48-46.jpg)

### Структура проєкту
Агент складається з двох модулів, та файлу config.json з якого зчитуються джерела для вибірки даних.

#### scrapper.js -> Функціональний модуль, що вибирає дані
Функціональна частина агенту(що збирає дані) виконана з використанням бібліотеки puppeteer, як інструменту для виклику браузеру та створення у ньому сторінки, з якої згодом, за допомогою селекторів, вибираються необхідні дані. Саме puppeteer був викорастий через його простоту, а також через те, що він вже частково знайомий авторам проэкту. Браузер створюється з параметром headless(за замовчуванням), тобто користувач його не бачить. Результати повертаються у вигляді об'єкта, що містить список резльтатів(оскільки за потреби можна збирати дані з більш ніж одного посту)

#### app.js -> "Стартовий" модуль, що ініціалізує скрипт, а також відображає шкалу прогресу і записує результат
Ця частина виконана з використанням таких модулів як queue-promise, fs, cliProgress та chalk. Функція записана до app.js створює чергу та шкалу прогресу, що виводиться до консолі.Ітерується файл config.json, на кожному кроці на початок черги ставиться завдання, що являє собою ініціалізацію функціональної частини агенту з ресурсом(узятим з дійсного на цьому кроці елементу з config) та числом, що визначає кількість постів, що нас цікавить з даного ресурсу, в якості параметрів. Результат передається до спеціального масиву. Також на кожному кроці оновлюється стан шкали прогресу. Також після виконання кожного завдання повторно оновлюється стан шкали прогресу. По закінченню завдань в черзі зупиняєтья шкала прогресу, а масив з отриманими даними записується до файлу у форматі JSON.

<a name="тести"></a>
## Тестування
Для виконання тестувань було використано модуль Jest, проте корректно створити працездатні тести не вдалось. Було прийнято рішення тестувати ПЗ власноруч.
Пряме тестування працездатності програми дало потрібні результати. Агент працює справно, повертає файл з зібраною інформацією [collectedData](https://github.com/sofiaguchenko/agent/blob/main/src/config/collectedData.json).
![photo1](https://github.com/sofiaguchenko/agent/blob/main/doc/ph/photo_2021-05-20_19-46-23.jpg)
Програма успішно зчитує та зберігає дані. Виконує всі поставлені для неї задачі.

<a name="висновки"></a>
## Висновки
В результаті виконання проєкту було розроблено агент вибірки даних з медіа-ресурсу, у нашому випадку Reddit.
Під час розробки даного продукту було в повному обсязі реалізовано технічне завдання, за допомогою готової програми можна виконати поставлені на початку роботи задачі.
Виконання курсової роботи допомогло закріпити матеріал і навички, отримані на лекціях з курсу «Інженерія програмного забезпечення» та освоїти новий матеріал, що ще не був вивчений у ході курсу, але став у пригоді  під час вирішення конкретних завдань.

<a name="джерела"></a>
## Джерела

[Мас-медіа](https://uk.wikipedia.org/wiki/%D0%97%D0%B0%D1%81%D0%BE%D0%B1%D0%B8_%D0%BC%D0%B0%D1%81%D0%BE%D0%B2%D0%BE%D1%97_%D1%96%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D1%96%D1%97)

[Соціальні медіа](https://uk.wikipedia.org/wiki/%D0%A1%D0%BE%D1%86%D1%96%D0%B0%D0%BB%D1%8C%D0%BD%D1%96_%D0%BC%D0%B5%D0%B4%D1%96%D0%B0)

[Контент-аналіз](https://uk.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BD%D1%82%D0%B5%D0%BD%D1%82-%D0%B0%D0%BD%D0%B0%D0%BB%D1%96%D0%B7#:~:text=%D0%9A%D0%BE%D0%BD%D1%82%D0%B5%D0%BD%D1%82-%D0%B0%D0%BD%D0%B0%D0%BB%D1%96%D0%B7%20%E2%80%94%20%D1%8F%D0%BA%D1%96%D1%81%D0%BD%D0%BE-%D0%BA%D1%96%D0%BB%D1%8C%D0%BA%D1%96%D1%81%D0%BD%D0%B8%D0%B9,%D1%82%D0%B5%D0%BA%D1%81%D1%82%D1%83%20%D0%B7%20%D0%BF%D0%BE%D0%B4%D0%B0%D0%BB%D1%8C%D1%88%D0%BE%D1%8E%20%D1%96%D0%BD%D1%82%D0%B5%D1%80%D0%BF%D1%80%D0%B5%D1%82%D0%B0%D1%86%D1%96%D1%94%D1%8E%20%D1%80%D0%B5%D0%B7%D1%83%D0%BB%D1%8C%D1%82%D0%B0%D1%82%D1%96%D0%B2)

[Reddit](https://uk.wikipedia.org/wiki/Reddit)

[Nodejs](https://uk.wikipedia.org/wiki/Node.js)

[Axios](https://web-standards.ru/articles/fetch-vs-axios/)

[Веб-скрапінг](https://habr.com/ru/company/ruvds/blog/486688/)

[tg-scrapper](https://github.com/boldak/tg-scrapper)
